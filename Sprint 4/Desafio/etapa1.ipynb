{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3444921",
   "metadata": {},
   "source": [
    "\n",
    "# Automação de Bucket S3 usando boto3\n",
    "\n",
    "Este notebook contém as etapas necessárias para automatizar a criação de um bucket S3, realizar o upload de um arquivo local para o bucket e listar os arquivos disponíveis no bucket.\n",
    "\n",
    "## Pré-requisitos\n",
    "\n",
    "### 1. Configurar o Ambiente Virtual\n",
    "\n",
    "1. Crie um ambiente virtual (recomendado para gerenciar dependências de forma isolada):\n",
    "    ```bash\n",
    "    python -m venv venv\n",
    "    ```\n",
    "\n",
    "2. Ative o ambiente virtual:\n",
    "    - No Windows:\n",
    "        ```bash\n",
    "        venv\\Scripts\\activate\n",
    "        ```\n",
    "    - No macOS/Linux:\n",
    "        ```bash\n",
    "        source venv/bin/activate\n",
    "        ```\n",
    "\n",
    "3. Instale as bibliotecas necessárias:\n",
    "    ```bash\n",
    "    pip install boto3 python-dotenv\n",
    "    ```\n",
    "\n",
    "### 2. Configurar as Credenciais da AWS\n",
    "\n",
    "Crie um arquivo `.env` na mesma pasta do notebook contendo as credenciais da AWS:\n",
    "```\n",
    "AWS_ACCESS_KEY_ID=seu_aws_access_key_id\n",
    "AWS_SECRET_ACCESS_KEY=seu_aws_secret_access_key\n",
    "AWS_SESSION_TOKEN=seu_aws_session_token\n",
    "REGION_NAME=us-east-1\n",
    "```\n",
    "\n",
    "Certifique-se de substituir os valores com suas credenciais reais.\n",
    "\n",
    "### 3. Escolher o Kernel no Jupyter Notebook\n",
    "\n",
    "Ao abrir o notebook no Jupyter, selecione o kernel associado ao ambiente virtual configurado (\"Python (venv)\"). Para alterar o kernel:\n",
    "1. Clique em **Kernel** no menu superior.\n",
    "2. Escolha **Change Kernel**.\n",
    "3. Selecione o kernel **Python (venv)**.\n",
    "\n",
    "### 4. Estrutura do Notebook\n",
    "\n",
    "Cada etapa do processo está separada em células, com explicações detalhadas sobre sua funcionalidade:\n",
    "\n",
    "- **Etapa 1:** Criar o bucket no S3.\n",
    "- **Etapa 2:** Fazer upload de um arquivo para o bucket.\n",
    "- **Etapa 3:** Listar os arquivos disponíveis no bucket.\n",
    "\n",
    "Você pode executar as células individualmente para testar cada funcionalidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880951d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Credenciais da AWS, se quiser pode colocar suas credenciais no arquivo .env\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_session_token = os.getenv('AWS_SESSION_TOKEN')\n",
    "region_name = os.getenv('REGION_NAME')\n",
    "\n",
    "# Inicializar o cliente S3\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    "    aws_session_token=aws_session_token,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Nome do bucket e caminho do arquivo local\n",
    "bucket_name = 'meu-bucket-sprint-4'  # Pode alterar para o nome do seu bucket\n",
    "local_file_path = 'consumo-energetico-por-campus.csv'  # Pode alterar para o arquivo desejado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a005364",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 1: Criar o Bucket no S3\n",
    "A função `criar_bucket` é responsável por criar um bucket no S3. Caso o bucket já exista ou ocorra algum erro, uma mensagem será exibida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785350d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando criar o bucket: meu-bucket-sprint-4\n",
      "Bucket 'meu-bucket-sprint-4' criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def criar_bucket(bucket_name):\n",
    "    print(f\"Tentando criar o bucket: {bucket_name}\")\n",
    "    try:\n",
    "        if region_name == 'us-east-1':\n",
    "            # Para us-east-1, não especificar LocationConstraint\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            # Para outras regiões, especificar LocationConstraint\n",
    "            s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': region_name}\n",
    "            )\n",
    "        print(f\"Bucket '{bucket_name}' criado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar o bucket: {e}\")\n",
    "\n",
    "# Executar a função\n",
    "criar_bucket(bucket_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc57ec1",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 2: Fazer Upload de um Arquivo\n",
    "A função `fazer_upload` realiza o upload de um arquivo local para o bucket especificado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334e59b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando fazer upload do arquivo: consumo-energetico-por-campus.csv\n",
      "Arquivo 'consumo-energetico-por-campus.csv' enviado para o bucket 'meu-bucket-sprint-4' com sucesso.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fazer_upload(bucket_name, local_file_path):\n",
    "    print(f\"Tentando fazer upload do arquivo: {local_file_path}\")\n",
    "    try:\n",
    "        s3.upload_file(local_file_path, bucket_name, os.path.basename(local_file_path))\n",
    "        print(f\"Arquivo '{local_file_path}' enviado para o bucket '{bucket_name}' com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao fazer upload do arquivo: {e}\")\n",
    "\n",
    "# Executar a função\n",
    "fazer_upload(bucket_name, local_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f62ba",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 3: Listar Arquivos no Bucket\n",
    "A função `listar_arquivos` lista todos os arquivos armazenados no bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492437cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando listar os arquivos no bucket: meu-bucket-sprint-4\n",
      "Arquivos no bucket:\n",
      " - consumo-energetico-por-campus.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def listar_arquivos(bucket_name):\n",
    "    print(f\"Tentando listar os arquivos no bucket: {bucket_name}\")\n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            print(\"Arquivos no bucket:\")\n",
    "            for obj in response['Contents']:\n",
    "                print(f\" - {obj['Key']}\")\n",
    "        else:\n",
    "            print(\"O bucket está vazio.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao listar os objetos no bucket: {e}\")\n",
    "\n",
    "# Executar a função\n",
    "listar_arquivos(bucket_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
